{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import urllib \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_links = []\n",
    "primary_links = []\n",
    "product_links = []\n",
    "titles = []\n",
    "kods=[]\n",
    "prices = []\n",
    "articles=[]\n",
    "categories=[]\n",
    "urles=[]\n",
    "\n",
    "\n",
    "url = 'http://shop.jonnesway.ru'\n",
    "r = requests.get(url)\n",
    "html_content = r.text\n",
    "soup = BeautifulSoup(html_content,'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll('a', attrs={'href': re.compile(\"/shop.jonnesway.ru/\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in soup.findAll('a', attrs={'href': re.compile(\"/shop.jonnesway.ru/\")}):\n",
    "    temporary_links.append(link.get('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_links=np.unique(temporary_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temporary_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jjjs=[]\n",
    "k=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in temporary_links:\n",
    "    url=link\n",
    "    r = requests.get(url)\n",
    "    html_content = r.text\n",
    "    soup = BeautifulSoup(html_content,'html.parser')\n",
    "    if soup.findAll('div',class_=\"results\")==[]:\n",
    "        m=5\n",
    "    else:    \n",
    "        voi=soup.findAll('div',class_=\"results\")[0].text.find('(')\n",
    "        bkl=soup.findAll('div',class_=\"results\")[0].text.find('страниц')\n",
    "        dod=int(soup.findAll('div',class_=\"results\")[0].text[voi+1:bkl-1])\n",
    "        for j in range(1,dod+1):\n",
    "            uril=url+'?page='+str(j)\n",
    "            r = requests.get(uril)\n",
    "            html_content = r.text\n",
    "            soup = BeautifulSoup(html_content,'html.parser')\n",
    "            position=len(soup.findAll('div',class_=\"image\"))\n",
    "            for jkl in range(position):\n",
    "                guo=str(soup.findAll('div',class_=\"image\")[jkl])[28:].find('\">')\n",
    "                jjj=str(soup.findAll('div',class_=\"image\")[jkl])[28:28+guo]\n",
    "                jjjs.append(jjj)\n",
    "    k=k+1\n",
    "    print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popopo=np.unique(jjjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kok=0\n",
    "for link in popopo[2238:]:\n",
    "    url=link\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        r.status_code = \"Connection refused\"\n",
    "    html_content = r.text\n",
    "    soup = BeautifulSoup(html_content,'html.parser')\n",
    "    \n",
    "    if soup.findAll('div',class_=\"product-section\")==[]:\n",
    "        kod=''\n",
    "    else:\n",
    "        lll=soup.findAll('div',class_=\"product-section\")[0]\n",
    "        kod=lll.text.split()[2]\n",
    "    kods.append(kod)\n",
    "    \n",
    "    \n",
    "    title=soup.findAll('h1',class_='view')[0].text\n",
    "    titles.append(title)\n",
    "    \n",
    "    \n",
    "    \n",
    "    article=lll.text.split()[4]\n",
    "    articles.append(article)\n",
    "    \n",
    "    price=soup.findAll('span',class_=\"price-new\")[0].text\n",
    "    prices.append(price)\n",
    "    \n",
    "    oo=list(soup.findAll('div',class_=\"breadcrumb\")[0])[-4]\n",
    "    aa=str(oo)[13:].find('>')\n",
    "    gg=str(oo)[13:].find('<')\n",
    "    category=str(oo)[aa+1+13:13+gg]\n",
    "    categories.append(category)\n",
    "    \n",
    "    urles.append(url)\n",
    "    kok=kok+1\n",
    "    print(kok)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(list(zip(titles,kods, articles, prices, categories,urles)), columns =['Наименование товара','Код','Артикул','Цена','Категория','Ссылка на товар']) \n",
    "\n",
    "table.to_excel('shop_jonnesway 6.5 1.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
