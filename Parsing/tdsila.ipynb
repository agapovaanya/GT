{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import urllib \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import _datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_datetime1 = datetime.datetime.now()\n",
    "temporary_links = []\n",
    "primary_links = []\n",
    "product_links = []\n",
    "titles = []\n",
    "prices = []\n",
    "marks=[]\n",
    "articles=[]\n",
    "valutes=[]\n",
    "categories=[]\n",
    "k=0\n",
    "m=0\n",
    "url = 'https://tdsila.ru/katalog/'\n",
    "r = requests.get(url)\n",
    "html_content = r.text\n",
    "soup = BeautifulSoup(html_content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_links=[]\n",
    "for link in soup.findAll('a',class_='katalog-subcategory-link'):\n",
    "    temporary_links.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_links_2=temporary_links_1[371:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temporary_links_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_links_3=[]\n",
    "#delet=[]\n",
    "for i in range(len(temporary_links_2)):\n",
    "    print(i)\n",
    "    url_0 = temporary_links_2[i]\n",
    "    r = requests.get(url_0)\n",
    "    html_content = r.text\n",
    "    soup = BeautifulSoup(html_content,'html.parser')\n",
    "    #proverka=[]\n",
    "    for m in soup.findAll('a',class_='col-sm-2 col-xs-6 category-block-link'):\n",
    "        temporary_links_3.append(m.get('href'))\n",
    "        #proverka.append(m.get('href'))\n",
    "    \n",
    "    #if proverka==[]:\n",
    "        #delet.append(url_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temporary_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_links_1=[]\n",
    "for m in soup.findAll('a',class_='col-sm-2 col-xs-6 category-block-link'):\n",
    "    temporary_links_1.append(m.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(6,len(temporary_links_1)):\n",
    "    print(i,'из 172')\n",
    "    url_0 = temporary_links[i]\n",
    "    r = requests.get(url_0)\n",
    "    html_content = r.text\n",
    "    soup = BeautifulSoup(html_content,'html.parser')\n",
    "    if soup.findAll('div',class_='col-sm-6 text-right')!=[]:\n",
    "        page_str=soup.findAll('div',class_='col-sm-6 text-right')[0].text\n",
    "        page_beg=page_str.find('всего ')+6\n",
    "        page_end=page_str.find('страниц)')-1\n",
    "        last_page=int(page_str[page_beg:page_end])\n",
    "        print(last_page)\n",
    "\n",
    "        for j in range(1,last_page+1):\n",
    "            url = url_0+'?page='+str(j)\n",
    "            print(url)\n",
    "            r = requests.get(url)\n",
    "            html_content = r.text\n",
    "            soup = BeautifulSoup(html_content,'html.parser')\n",
    "\n",
    "            all_link=soup.findAll('div',class_='name')\n",
    "            for i in range(len(all_link)):\n",
    "                a=str(soup.findAll('div',class_='name')[i])\n",
    "                begin=str(soup.findAll('div',class_='name')[i]).find('href=')+4\n",
    "                et2=a[begin+2:]\n",
    "                end=et2.find('\">')\n",
    "                link=et2[:end]\n",
    "                links.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_links=np.unique(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uniq_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_all=[]\n",
    "article_all=[]\n",
    "price_all=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(2039,len(uniq_links)):\n",
    "    print(i)\n",
    "    name=''\n",
    "    article=''\n",
    "    price=''\n",
    "    url = uniq_links[i]\n",
    "    r = requests.get(url)\n",
    "    html_content = r.text\n",
    "    soup = BeautifulSoup(html_content,'html.parser')\n",
    "    if soup.findAll('span',itemprop='price')!=[]:\n",
    "        price=soup.findAll('span',itemprop='price')[0].text\n",
    "    if soup.findAll('span',class_='product-sku')!=[]:\n",
    "        article=soup.findAll('span',class_='product-sku')[0].text\n",
    "    if soup.findAll('h1')!=[]:\n",
    "        name=soup.findAll('h1')[0].text\n",
    "    \n",
    "    name_all.append(name)\n",
    "    article_all.append(article)\n",
    "    price_all.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(list(zip(name_all, article_all,price_all,uniq_links))) \n",
    "\n",
    "table.to_excel('tdsila030621.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
