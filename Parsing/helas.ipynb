{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import urllib \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import _datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://helas.ru/catalog/'\n",
    "r = requests.get(url)\n",
    "html_content = r.text\n",
    "soup = BeautifulSoup(html_content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ=soup.findAll('td',class_='image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(categ)):\n",
    "    category.append(categ[i].find('a').get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcategory=[]\n",
    "for j in range(len(category)):\n",
    "    print(j)\n",
    "    url ='https://helas.ru'+category[j]\n",
    "    r = requests.get(url)\n",
    "    html_content = r.text\n",
    "    soup = BeautifulSoup(html_content,'html.parser')\n",
    "    \n",
    "    podcat=soup.findAll('a',class_='muted777')\n",
    "    for i in range(len(podcat)):\n",
    "        podcategory.append(podcat[i].get('href'))\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(podcategory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(podcategory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "podcate=[]\n",
    "\n",
    "for j in range(len(podcategory)):\n",
    "    print(j)\n",
    "    url ='https://helas.ru'+podcategory[j]\n",
    "    r = requests.get(url)\n",
    "    html_content = r.text\n",
    "    soup = BeautifulSoup(html_content,'html.parser')\n",
    "    vse=soup.findAll('li',class_='name')    \n",
    "    for i in range(len(vse)):\n",
    "        podcate.append(vse[i].find('a').get('href'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(podcate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neponyatno=[]\n",
    "for h in range(len(podcate)):\n",
    "    url ='https://helas.ru'+podcate[h]\n",
    "    r = requests.get(url)\n",
    "    html_content = r.text\n",
    "    soup = BeautifulSoup(html_content,'html.parser')\n",
    "    if soup.findAll('a',class_='dark_link option-font-bold font_sm') ==[]:\n",
    "        neponyatno.append(url)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_category=podcate+podcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linki=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(308,len(all_category)):\n",
    "    print(t)\n",
    "    url ='https://helas.ru'+all_category[t]\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except:\n",
    "        print('uuuu')\n",
    "    \n",
    "    html_content = r.text\n",
    "    soup1 = BeautifulSoup(html_content,'html.parser')\n",
    "    if soup1.findAll('div',class_='nums')==[]:\n",
    "        link=soup1.findAll('a',class_='thumb')\n",
    "        for u in range(len(link)):\n",
    "            linki.append(link[u].get('href'))\n",
    "\n",
    "    else:\n",
    "        last_page=int(soup1.findAll('div',class_='nums')[0].findAll('a',class_='dark_link')[-1].text)\n",
    "        for j in range(1,last_page+1):\n",
    "            print(j,'page')\n",
    "            url1 =url+'?PAGEN_1='+str(j)\n",
    "            try:\n",
    "                r1 = requests.get(url1)\n",
    "            except:\n",
    "                print('uuuu')\n",
    "            \n",
    "            html_content1 = r1.text\n",
    "            soup2 = BeautifulSoup(html_content1,'html.parser')\n",
    "            link=soup2.findAll('a',class_='thumb')\n",
    "            for u in range(len(link)):\n",
    "                linki.append(link[u].get('href'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linki=np.unique(linki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_all=[]\n",
    "brand_all=[]\n",
    "price_all=[]\n",
    "article_all=[]\n",
    "code_all=[]\n",
    "link_all=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(linki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in range(len(linki)):\n",
    "    print(h)\n",
    "    url ='https://helas.ru'+linki[h]\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except:\n",
    "        print('kkklkl')\n",
    "    html_content = r.text\n",
    "    soup = BeautifulSoup(html_content,'html.parser')\n",
    "    brand=''\n",
    "    price=''\n",
    "    code=''\n",
    "    article=''\n",
    "    name=''\n",
    "    #brand\n",
    "    if soup.findAll('a',class_='brand__link dark_link')!=[]:\n",
    "        brand=soup.findAll('a',class_='brand__link dark_link')[0].text\n",
    "    else:\n",
    "        if soup.findAll('div',class_='brand')!=[]:\n",
    "            brand=soup.findAll('div',class_='brand')[0].find('img').get('alt')\n",
    "\n",
    "        #price \n",
    "    if soup.findAll('div', class_=\"product-info-wrapper\")!=[]:\n",
    "        beg=str(soup.findAll('div', class_=\"product-info-wrapper\")[0].find('script')).find('DISCOUNT_VALUE')\n",
    "        end=str(soup.findAll('div', class_=\"product-info-wrapper\")[0].find('script'))[beg+17:].find(',')\n",
    "        price=str(soup.findAll('div', class_=\"product-info-wrapper\")[0].find('script'))[beg+17:beg+17+end-1]   \n",
    "\n",
    "    #article and code\n",
    "    for i in soup.findAll('div',class_='properties__item properties__item--compact font_xs'):\n",
    "        if i.text.find('Артикул')>0:\n",
    "            article=i.text.replace('\\n','').replace('\\t','')[8:]\n",
    "        if i.text.find('Код')>0:\n",
    "            code=i.text.replace('\\n','').replace('\\t','')[4:]\n",
    "\n",
    "    name=soup.findAll('h1')[0].text\n",
    "\n",
    "    name_all.append(name)\n",
    "    brand_all.append(brand)\n",
    "    price_all.append(price)\n",
    "    article_all.append(article)\n",
    "    code_all.append(code)\n",
    "    link_all.append(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(list(zip(name_all, brand_all,article_all,code_all,price_all,link_all)), columns =['Наименование товара', 'Бренд', 'Артикул','Код','Цена','Ссылка на товар']) \n",
    "\n",
    "table.to_excel('helas300721.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
