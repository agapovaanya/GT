{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import urllib \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporary_links = []\n",
    "primary_links = []\n",
    "product_links = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.jtcrussia.ru'\n",
    "r = requests.get(url)\n",
    "html_content = r.text\n",
    "soup = BeautifulSoup(html_content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in soup.findAll('a', attrs={'href': re.compile(\"/catalog/\")}):\n",
    "    temporary_links.append(link.get('href'))\n",
    "temporary_links=temporary_links[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kio=0\n",
    "lio=len(temporary_links)\n",
    "for temporary_link in temporary_links:\n",
    "    kio+=1\n",
    "    url='https://www.jtcrussia.ru'+temporary_link\n",
    "    r = requests.get(url)\n",
    "    html_content = r.text\n",
    "    soup = BeautifulSoup(html_content,'html.parser')\n",
    "    if soup.findAll('li', class_=\"last\")==[]:\n",
    "        for link in soup.findAll('a', attrs={'href': re.compile(\"/tools/\")}):\n",
    "            product_links.append(link.get('href'))\n",
    "    else:       \n",
    "        a=str(soup.findAll('li', class_=\"last\")[0])\n",
    "        last_pages=int(a[(a.find('?page='))+6:-11])\n",
    "        for i in range(1,last_pages+1):\n",
    "            print(kio,lio,i,last_pages)\n",
    "            url_vn=url+'?page='+str(i)\n",
    "            r = requests.get(url_vn)\n",
    "            html_content = r.text\n",
    "            soup = BeautifulSoup(html_content,'html.parser')\n",
    "            for link in soup.findAll('a', attrs={'href': re.compile(\"/tools/\")}):\n",
    "                product_links.append(link.get('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_links_unique=np.unique(product_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "prices = []\n",
    "marks=[]\n",
    "articles=[]\n",
    "valutes=[]\n",
    "categories=[]\n",
    "urles=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mio=0\n",
    "for product_link in product_links_unique[3323:]:\n",
    "    mio+=1\n",
    "    print(mio)\n",
    "    url = 'https://www.jtcrussia.ru' + product_link\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        r.status_code = \"Connection refused\"\n",
    "    html_content = r.text\n",
    "    soup = BeautifulSoup(html_content,'html.parser')\n",
    "\n",
    "    title = soup.findAll('h1')[-1].text\n",
    "    titles.append(title)\n",
    "\n",
    "        \n",
    "    article=soup.findAll('p',class_='article')[0].text\n",
    "    articles.append(article)\n",
    "\n",
    "    price=''\n",
    "    aaaa=soup.findAll('u')[0].text.split()[:-1]\n",
    "    for i in range(int(len(aaaa))):\n",
    "        price=price+aaaa[i]\n",
    "    prices.append(price)\n",
    "        \n",
    "    if len(soup.findAll('h1'))==1:\n",
    "        lo='iii'\n",
    "    else:\n",
    "        lo=str(soup.findAll('h1')[-2]).split()\n",
    "    \n",
    "    k=0\n",
    "    for i in range(int(len(lo))):\n",
    "        if lo[i]=='<span></span></div>':\n",
    "            k=i+1\n",
    "        brand=lo[k:-1]\n",
    "    b=''\n",
    "    for i in range(int(len(brand))):\n",
    "        b=str(b)+' '+brand[i]\n",
    "    category=b[1:]\n",
    "    categories.append(category)\n",
    "        \n",
    "    urles.append(url)\n",
    "\n",
    "#product_linkks =[ 'https://www.jtcrussia.ru%s'%x for x in product_links_unique ]\n",
    "\n",
    "table = pd.DataFrame(list(zip(titles, articles,prices, categories,urles)), columns =['Наименование товара', 'Артикул','Цена','Категория','Ссылка на товар']) \n",
    "\n",
    "table.to_excel('jtc 100321.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
